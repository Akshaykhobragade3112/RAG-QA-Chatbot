# RAG-based QA Bot
This project implements a Retrieval-Augmented Generation (RAG) Model for a Question Answering (QA) bot using a vector database for document retrieval and a generative model for answering queries. 
The interactive interface allows users to upload PDF documents and ask questions based on their content.

## Table of Contents
Introduction \
Features \
Installation \
Usage \
File Structure \
Technologies Used \
Future Enhancements

## Introduction
The QA bot is built using a RAG approach where:

Document embeddings are stored using FAISS for efficient retrieval.
OpenAI GPT-3.5-turbo generates answers based on the relevant documents retrieved.
This bot can process PDF files, extract text, and allow users to ask questions about the uploaded documents. The bot retrieves relevant documents from a vector database and uses them to generate coherent responses.

## Features
#### Document Upload: 
Upload multiple PDF files. 

#### Document Embedding: 
Store document embeddings using FAISS for fast retrieval. 
#### Real-Time QA: 
Ask questions based on uploaded documents and get answers generated by GPT-3.5-turbo. 
#### Contextual Responses: 
The bot retrieves document context before generating answers, ensuring relevance.

## Installation
To run this project locally, follow the steps below:
### Clone the Repository :
    git clone https://github.com/Akshaykhobragade3112/RAG-QA-Chatbot.git
    cd RAG-QA-Chatbot
### Install Dependencies
    pip install -r requirements.txt
### Set up API Keys
    You need to provide your OpenAI API key by setting it as an environment variable:
    export OPENAI_API_KEY="your-openai-api-key"

## Usage
1. Run the Streamlit App:
   To start the interactive QA bot, run the following command:
   streamlit run app.py
2. Upload Documents:
   In the web interface, upload one or more PDF files.
   The bot will extract text from the uploaded documents and store the embeddings.
3. Ask a Question:
   Once documents are uploaded, enter your question into the text input field.
   The bot retrieves relevant document segments and generates an answer based on the content.
4. View Results:
   The generated answer is displayed along with the retrieved document context.

## File Structure:
   RAG-QA-Chatbot/ \
   ├── app.py                ( The Streamlit frontend application) \
   ├── rag_model.py          ( Backend logic for document embedding and question answering) \
   ├── requirements.txt      ( Required Python dependencies) \
   └── README.md             ( This readme file)
### Explanation of Key Files:
  1.app.py: Contains the Streamlit code for the user interface, allowing file upload, document processing, and interaction with the RAG model. \
  2.rag_model.py: Implements the core logic for embedding documents, retrieving relevant documents, and generating answers using OpenAI GPT-3.5-turbo. \
  3.requirements.txt: Lists all required dependencies for the project.
  
## Technologies Used
OpenAI GPT-3.5-turbo for generating answers. 

FAISS for fast vector-based similarity search.

Sentence Transformers for document embeddings.

Streamlit for creating an interactive user interface.

PyPDF2 for PDF text extraction.

Python as the primary programming language.

## Future Enhancements
Implement Pinecone DB: Optionally, replace FAISS with Pinecone for better scalability in handling large datasets.

Error Handling: Add better error handling and user feedback for failed API calls or document processing issues.

Caching: Implement caching for faster query responses
